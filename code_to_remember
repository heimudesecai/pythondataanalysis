list1.index('abcde') #get the index of 'abcde' in list1

list1[::-1] #inverse list1. Don't change list1
list1.reverse() #reverse list1 inplace

pd.read_csv('file', sep='|', names=columns, index_col='movie_id', encoding="ISO-8859-1")

sorted(dict1.items(), key= lambda k: k[1]) #sort dict1 based on the value. return list of tuple
sorted(dict1, key= lambda k: k[1]) #sort dict1 based on the value. return list of key
df1.sort_values('year', ascending=True) #dataframe sort based on 'year'

df1.dropna(subset=['year'], inplace=False) #delete rows whose 'year' is nan

df1[df1["year"].isin(list1)] #select rows whose 'year' in list1

pd.DatetimeIndex(df1['date']) #change 'date' column to 'datetime64[ns]' type
pd.DatetimeIndex(df1['date'].fillna(0)).year.astype(int) # get year from 'date' and change it to int type
pd.to_datetime(df1["timestamp"], unit = "s") # change 'timestamp' to datetime64[ns] type
pd.to_datetime(df1["timestamp"], unit = "s").dt.year # df1['timestamp'] is # of seconds since 1970. Change it to date and get the year

df.rename(columns={'col1': "col2"}, inplace = True) #change the name of one column

df1.groupby('col1').agg(['min', 'max']) #group by col1. calculate 'min' and 'max' of all other columns
df1.groupby('col1').col2.agg(['count', 'mean']) #group by col1. calculate 'count' and 'mean' of col2
df1.groupby('col1').col2.agg({'col2_count': 'count', 'col2_mean': 'mean'}) #define the column name
df1.groupby('col1').agg({'col2': ['min', 'max'], 'col3': min})

df1.pivot_table(index = 'col1', columns = 'col2', values = 'col3', aggfunc = 'max', fill_value = 0) 
#All distinct values of col1 become index. All distinct values of col2 become column name. Values are col3.

different multiply
(1) A * B, np.multiply(A, B)
- vector: element wise
- matrix: element wise
(2) A @ B, np.dot(A, B)
- vector: element-wise and sum
- matrix: linear algebra multiply
(3) np.outer(A, B)
- w = np.array([5, 7])
  np.outer(w, w)
  output: array([[25, 35],
                 [35, 49]])

sparse matrix
>>> X_sparse = sp.coo_matrix([[5., 0., 0.], [1., 1., 0.]])
>>> sp.coo_matrix(([-np.inf] * X_sparse.data.shape[0], (X_sparse.row, X_sparse.col)), shape = X_sparse.shape)
output: matrix([[-inf,   0.,   0.],
                [-inf, -inf,   0.]])
# X_sparse.data: all data in X_sparse that is not 0
# X_sparse.row, X_sparse.col: the row and col of data in X_sparse

(1) sp.coo_matrix: data, column index, row index
>>> data = [2, 4, 1, 3, 1, 1]
>>> row = [1, 3, 2, 0, 3, 1]
>>> col = [0, 0, 1, 2, 2, 3]
>>> m = sp.coo_matrix((data, (row, col)), shape = (4, 4))
>>> m.A
[[0 0 3 0]
 [2 0 0 1]
 [0 1 0 0]
 [4 0 1 0]]
 
(2) sp.csc_matrix
>>> indptr = np.array([0, 2, 3, 6]) #data[0:2] -> col0; data[2:3] -> col1; data[3:6] -> col2
>>> indices = np.array([0, 2, 2, 0, 1, 2])
>>> data = np.array([1, 2, 3, 4, 5, 6])
>>> sparse.csc_matrix((data, indices, indptr), shape=(3, 3)).toarray()
array([[1, 0, 4],
       [0, 0, 5],
       [2, 3, 6]])
m.tocsc() #Convert m to csc. CSC matrix allows for fast column access
X_csc.getcol(j).A.ravel() #.getcol(j) get the jth column. .A converts the sparse matrix to its dense representation (of type np.ndarray)
#.ravel convert 2D matrix to vector

(3) sp.csr_matrix   
>>> indptr = np.array([0, 2, 3, 6]) #data[0:2] -> row0; data[2:3] -> row1; data[3:6] -> row2
>>> indices = np.array([0, 2, 2, 0, 1, 2])
>>> data = np.array([1, 2, 3, 4, 5, 6])
>>> sparse.csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()
array([[1, 0, 2],
       [0, 0, 3],
       [4, 5, 6]])
m.tocsr() #Convert m to CSR. CSR matrix allows for fast row access
X_csr.getrow(i)

If an operation is supported by both scipy.sparse and numpy, always use the scipy.sparse version. 
Sometimes the numpy version will convert the sparse matrix input to dense matrix. 
For example, use A.dot(x) instead of np.dot(A, x)

x.astype(np.float64) #change the datatype of np.array x

1D arrays in Numpy are always treated as column vectors. shape is (k,). If A is 1D arrays, A and A.T are the same.

Broadcasting:
A and B have the same shape in the same axis. Or one of them has shape 1 in the same axis.

Use None to change the shape:
b = np.array(10) #0D, 10
b_1d = b[None] #turn 0D to 1D, [10]
b_2d = b[None, None] #turn 0D to 2D, [[10]]
b_1d[:, None] #turn 1D to 2D, [[10]]
v = np.array([1, 3])
w = np.array([5, 7])
print(np.outer(v, w))
print(v[:,None] @ w[:,None].T)
[[ 5  7]
 [15 21]]
 
df[~df["First Name"].isin(["Jim", "Kim"])] # ~ negation symbol
df.query('`First Name` in ["Jim", "Kim"]') # use a query string to select rows

Iterate through rows:
eg. use "first name" and "last name" to add a new column "full name"
(1) .iloc along with row index
for i in range(len(df)):
    df.loc[i, "Full Name 1"] = df.loc[i, "First Name"] + " " + df.loc[i, "Last Name"]
(2) iterrows method
full_names = []
for row_index, row in df.iterrows():
    full_names.append(row["First Name"] + " " + row["Last Name"])
df["Full Name 2"] = full_names
(3) apply with axis=1
df["Full Name 3"] = df.apply(lambda x: x["First Name"] + " " + x["Last Name"], axis=1) #x represents each row
(4) Pandas vectorization
df["Full Name 4"] = df["First Name"] + " " + df["Last Name"]

vectorization 
https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6
https://datascience.blog.wzb.eu/2018/02/02/vectorization-and-parallelization-in-python-with-numpy-and-pandas/

wide format vs long format
wide formate: 
- each raw represents an observation
- each column represents a feature
long format: 
- one or more raws represent an observation 
- one column for the observation ID, one column for feature's name, and one for feature's value

wide to long:
df_wide.melt(id_vars = ["ID"], value_vars = ["full name", "sex"], var_name = "feature", value_name = "value")
- id_vars: names of the columns with the observation IDs
- value_vars: names of the feature columns
- var_name: name of the new column that will contain the feature names
- value_name: name of the new column that will contain the feature values.
output:
       ID   feature    value
   0   s1   full name  Smith
   1   s1   sex        male
   2   s2   full name  Mary
   3   s3   sex        female

long to wide:
df_long.pivot_table(index = "ID", columns = "feature", values = "value")
- index: name of the column with the ids.
- columns: name of the column that contains the feature names.
- values: name of the column that contains the feature values.
output:
      feature    full name   sex
      ID
      s1         Smith       male
      s2         Mary        female
